üß† LSTM-RNN: Next Word Prediction
An end-to-end deep learning application that predicts the next word in a sequence using Long Short-Term Memory networks, trained on Shakespeare's Hamlet.

![Python](https://img.shields.io/badge/python-3.8+-blue.svg) ![TensorFlow](https://img.shields.io/badge/TensorFlow-2.0+-orange.svg) ![Flask](https://img.shields.io/badge/Flask-2.0+-green.svg) ![License](https://img.shields.io/badge/license-MIT-blue.svg)

[Features](#-features) ‚Ä¢ [Installation](#-installation) ‚Ä¢ [Usage](#-usage) ‚Ä¢ [API](#-api-endpoints) ‚Ä¢ [Troubleshooting](#-troubleshooting)

---

## üéØ Overview

LSTM-based text generation system that predicts the next word in a sequence. Trained on Shakespeare's Hamlet for sophisticated language understanding.

### Key Highlights

üé® **Intuitive Interface**: User-friendly web application  
ü§ñ **Deep Learning**: LSTM architecture with 91%+ accuracy  
üöÄ **Production Ready**: Flask REST API  
üìä **Literary Training**: Trained on classic literature  

---

## ‚ú® Features

### Deep Learning
‚úÖ LSTM-based sequence modeling  
‚úÖ Context-aware word prediction  
‚úÖ Pre-trained model with saved weights  
‚úÖ Real-time predictions  

### Application
‚úÖ RESTful API with Flask  
‚úÖ Interactive web interface  
‚úÖ Input validation  
‚úÖ Multiple prediction suggestions  

---

## üèóÔ∏è Project Structure

```
LSTM-RNN/
‚îú‚îÄ‚îÄ app.py                    # Flask application
‚îú‚îÄ‚îÄ experiment.ipynb          # Model training notebook
‚îú‚îÄ‚îÄ hamlet.txt               # Training data
‚îú‚îÄ‚îÄ next_word_lstm.h5        # Trained model
‚îú‚îÄ‚îÄ tokenizer.pickle         # Saved tokenizer
‚îú‚îÄ‚îÄ requirements.txt         # Dependencies
‚îî‚îÄ‚îÄ README.md               # Documentation
```

---

## üöÄ Installation

### Prerequisites
- Python 3.8+
- pip package manager

### Setup

**1. Clone repository**
```bash
git clone https://github.com/pinkidagar18/LSTM-RNN.git
cd LSTM-RNN
```

**2. Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

**3. Install dependencies**
```bash
pip install -r requirements.txt
```

**4. Run application**
```bash
python app.py
```

**5. Access at:** `http://localhost:5000`

---

## üìñ Usage

### Web Interface

1. Navigate to the homepage
2. Enter text sequence (e.g., "to be or not to")
3. Click "Predict Next Word"
4. View prediction with confidence score

### Example Predictions

| Input | Predicted Word | Confidence |
|-------|---------------|------------|
| "to be or not to" | "be" | 87.3% |
| "what light through yonder" | "window" | 92.1% |
| "the course of true" | "love" | 85.6% |

---

## üîå API Endpoints

### `GET /`
Returns landing page

### `GET /predict`
Returns prediction form

### `POST /predict`
Generates next word prediction

**Request:**
```bash
curl -X POST http://localhost:5000/predict -d "text=to be or not to"
```

**Response:**
```json
{
  "input_text": "to be or not to",
  "predicted_word": "be",
  "confidence": 0.873
}
```

---

## üß™ Model Details

### Architecture

```
Embedding (256 dims) ‚Üí LSTM (128) ‚Üí LSTM (128) ‚Üí Dense (Softmax)
```

### Hyperparameters

| Parameter | Value |
|-----------|-------|
| Embedding Dimension | 256 |
| LSTM Units | 128 |
| Dropout Rate | 0.2 |
| Sequence Length | 20 |
| Batch Size | 128 |
| Epochs | 100 |
| Optimizer | Adam |
| Learning Rate | 0.001 |

### Performance

| Metric | Training | Validation |
|--------|----------|------------|
| Accuracy | 94.2% | 91.5% |
| Loss | 0.185 | 0.248 |
| Perplexity | 12.3 | 15.7 |

---

## üìä Dataset

- **Source**: Shakespeare's Hamlet
- **Total Words**: ~30,000
- **Vocabulary**: ~4,500 unique words
- **Training Sequences**: ~28,000
- **Split**: 90% train, 10% validation

---

## üõ†Ô∏è Technologies

- **Python 3.8+**: Programming language
- **TensorFlow/Keras**: Deep learning framework
- **Flask**: Web framework
- **NumPy**: Numerical computing
- **Pickle**: Serialization

---

## üêõ Troubleshooting

### Issue 1: `ModuleNotFoundError: No module named 'tensorflow'`

**Problem:** TensorFlow is not installed.

**Solution:**
```bash
# Install TensorFlow
pip install tensorflow

# Verify installation
python -c "import tensorflow as tf; print(tf.__version__)"

# For Apple Silicon (M1/M2 Mac)
pip install tensorflow-macos tensorflow-metal
```

---

### Issue 2: `FileNotFoundError: next_word_lstm.h5`

**Problem:** Model file not found or running from wrong directory.

**Solution:**
```bash
# Verify you're in project root
pwd  # Should show /path/to/LSTM-RNN

# Check if files exist
ls next_word_lstm.h5 tokenizer.pickle

# If missing, retrain model
jupyter notebook experiment.ipynb
# Run all cells to generate model files
```

---

### Issue 3: Port 5000 already in use

**Problem:** Another application is using port 5000.

**Solution:**
```bash
# Linux/Mac - Kill process
lsof -i :5000
kill -9 <PID>

# Windows - Kill process
netstat -ano | findstr :5000
taskkill /PID <PID> /F

# Alternative: Use different port
# Edit app.py: app.run(port=8080)
```

---

### Issue 4: Virtual environment not activating (Windows)

**Problem:** PowerShell script execution is disabled.

**Solution:**
```powershell
# Enable script execution
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser

# Activate virtual environment
.\venv\Scripts\Activate.ps1
```

---

### Issue 5: `pip install` fails with dependency conflicts

**Problem:** Package version conflicts.

**Solution:**
```bash
# Upgrade pip first
python -m pip install --upgrade pip

# Clear cache and reinstall
pip cache purge
pip install -r requirements.txt

# If still fails, create fresh environment
deactivate
rm -rf venv
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

### Issue 6: `MemoryError` during prediction

**Problem:** Insufficient RAM or large batch size.

**Solution:**
```python
# Reduce batch size in app.py
predictions = model.predict(sequence, batch_size=1, verbose=0)

# Clear session after prediction
from tensorflow.keras import backend as K
K.clear_session()

# Force CPU usage if GPU memory issues
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
```

---

### Issue 7: Poor prediction accuracy

**Problem:** Model not trained properly or needs more epochs.

**Solution:**
```python
# Retrain with adjusted parameters in experiment.ipynb
history = model.fit(
    X_train, y_train,
    epochs=150,  # Increase epochs
    batch_size=64,
    validation_split=0.1,
    callbacks=[early_stopping, model_checkpoint]
)

# Increase model complexity
model = Sequential([
    Embedding(vocab_size, 256),
    LSTM(256, return_sequences=True),  # Increase units
    Dropout(0.3),
    LSTM(256),
    Dropout(0.3),
    Dense(vocab_size, activation='softmax')
])
```

---

### Issue 8: `jinja2.exceptions.TemplateNotFound: index.html`

**Problem:** Flask cannot find template files.

**Solution:**
```bash
# Verify correct folder structure
LSTM-RNN/
‚îú‚îÄ‚îÄ app.py
‚îî‚îÄ‚îÄ templates/    # Must be named exactly "templates"
    ‚îú‚îÄ‚îÄ index.html
    ‚îî‚îÄ‚îÄ predict.html

# Run from project root
cd /path/to/LSTM-RNN
python app.py
```

---

### Issue 9: Slow prediction time

**Problem:** Model loading on every request.

**Solution:**
```python
# Load model ONCE at startup (global scope in app.py)
print("Loading model...")
model = load_model('next_word_lstm.h5')
with open('tokenizer.pickle', 'rb') as f:
    tokenizer = pickle.load(f)
print("Model ready!")

# NOT inside route function
@app.route('/predict', methods=['POST'])
def predict():
    # Use pre-loaded model here
    result = model.predict(sequence, batch_size=1, verbose=0)
```

---

### Issue 10: Out of vocabulary (OOV) words

**Problem:** Input contains words not in training data.

**Solution:**
```python
def handle_oov_words(text, tokenizer):
    """Handle unknown words gracefully"""
    words = text.lower().split()
    known_words = [w for w in words if w in tokenizer.word_index]
    
    if not known_words:
        return None, "No known words in input"
    
    filtered_text = ' '.join(known_words)
    
    if len(known_words) < len(words):
        removed = set(words) - set(known_words)
        warning = f"Unknown words removed: {', '.join(removed)}"
        return filtered_text, warning
    
    return text, None

# Use in prediction
filtered_text, warning = handle_oov_words(user_input, tokenizer)
if filtered_text:
    prediction = predict_next_word(model, tokenizer, filtered_text)
```

---

### Still Having Issues?

**Quick Diagnostics:**
```bash
# Check Python version (should be 3.8+)
python --version

# Verify all files exist
ls -la *.h5 *.pickle *.txt

# Test model independently
python -c "from tensorflow.keras.models import load_model; load_model('next_word_lstm.h5'); print('‚úì Model OK')"

# Check package versions
pip list | grep -E "tensorflow|flask|numpy"
```

**Get Help:**
- üêõ [Open an issue](https://github.com/pinkidagar18/LSTM-RNN/issues)
- üìß Email: pinkidagar18@gmail.com

---

## ü§ù Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

---

## üìù License

MIT License -  

---

## üë§ Author

**Pinki**

üìß pinkidagar18@gmail.com  
üíª [@pinkidagar18](https://github.com/pinkidagar18)  
üîó [Project Link](https://github.com/pinkidagar18/LSTM-RNN)

---

 - Research and inspiration

---

<div align="center">

### Made with ‚ù§Ô∏è by Pinki

**‚≠ê Star this repo if you found it helpful!**

</div>
